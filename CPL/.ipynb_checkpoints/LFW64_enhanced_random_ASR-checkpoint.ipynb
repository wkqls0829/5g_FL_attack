{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NWa7Xo6PkIl3",
    "outputId": "b186c3b3-e0cf-423c-922c-94e64702f818"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kjb/.conda/envs/lora/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1+cu113 0.13.1+cu113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NVIDIA RTX A5000'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import grad\n",
    "import torchvision\n",
    "from torchvision import models, datasets, transforms\n",
    "import torch.nn.functional as func\n",
    "#torch.manual_seed(50)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(torch.__version__, torchvision.__version__)\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda:0\n"
     ]
    }
   ],
   "source": [
    "# dst = datasets.CIFAR100(\"~/.torch\", download=True)\n",
    "# dst = datasets.MNIST(\"~/.torch\", download=True)\n",
    "\n",
    "tp = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.CenterCrop(64),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "tt = transforms.ToPILImage()\n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "print(\"Running on %s\" % device)\n",
    "\n",
    "def label_to_onehot(target, num_classes=10):\n",
    "    target = torch.unsqueeze(target, 1)\n",
    "    onehot_target = torch.zeros(target.size(0), num_classes, device=target.device)\n",
    "    onehot_target.scatter_(1, target, 1)\n",
    "    return onehot_target\n",
    "\n",
    "def cross_entropy_for_onehot(pred, target):\n",
    "    return torch.mean(torch.sum(- target * F.log_softmax(pred, dim=-1), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AorI020iVjjS"
   },
   "outputs": [],
   "source": [
    "# def weights_init(m):\n",
    "#     if hasattr(m, \"weight\"):\n",
    "#         m.weight.data.uniform_(-0.5, 0.5)\n",
    "#         nn.init.xavier_uniform_(m.weight.data)\n",
    "#     if hasattr(m, \"bias\"):\n",
    "#         #m.bias.data.uniform_(-0.5, 0.5)\n",
    "#         #nn.init.xavier_uniform(m.bias.data)\n",
    "#         m.bias.data.fill_(0)\n",
    "\n",
    "\n",
    "\n",
    "# class LeNet(nn.Module):\n",
    "\n",
    "#     def __init__(self):\n",
    "\n",
    "#         super(LeNet, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 6, kernel_size=5,stride=2)\n",
    "#         self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=2)\n",
    "#         self.fc1 = nn.Linear(16*5*5, 256)\n",
    "#         self.fc2 = nn.Linear(256, 120)\n",
    "#         self.fc3 = nn.Linear(120, 106)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         #x = func.relu(self.conv1(x))\n",
    "#         x = func.sigmoid(self.conv1(x))\n",
    "#         #x = func.max_pool2d(x, 2)\n",
    "#         #x = func.relu(self.conv2(x))\n",
    "#         x = func.sigmoid(self.conv2(x))\n",
    "#         #x = func.max_pool2d(x, 2)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         #x = func.relu(self.fc1(x))\n",
    "#         x = func.sigmoid(self.fc1(x))\n",
    "#         #x = func.relu(self.fc2(x))\n",
    "#         x = func.sigmoid(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "#         return x\n",
    "\n",
    "    \n",
    "    \n",
    "# def weights_init(m):\n",
    "#     if hasattr(m, \"weight\"):\n",
    "#         m.weight.data.uniform_(-0.3, 0.3)\n",
    "#     if hasattr(m, \"bias\"):\n",
    "#         m.bias.data.uniform_(-0.3, 0.3)\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    if hasattr(m, \"weight\"):\n",
    "        m.weight.data.uniform_(-0.1, 0.1)\n",
    "    if hasattr(m, \"bias\"):\n",
    "        m.bias.data.uniform_(-0.1, 0.1)\n",
    "\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        act = nn.Sigmoid\n",
    "        #act = nn.Tanh\n",
    "        #act = nn.ReLU\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(3, 256, kernel_size=5, padding=5//2, stride=2),\n",
    "            act(),\n",
    "            nn.Conv2d(256, 256, kernel_size=5, padding=5//2, stride=2),\n",
    "            act(),\n",
    "            nn.Conv2d(256, 256, kernel_size=5, padding=5//2, stride=1),\n",
    "            act(),\n",
    "            nn.Conv2d(256, 256, kernel_size=5, padding=5//2, stride=1),\n",
    "            act(),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(65536, 106)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        # print(out.size())\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "    \n",
    "class LeNet_attack(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet_attack, self).__init__()\n",
    "        act = nn.Sigmoid\n",
    "        #act = nn.Tanh\n",
    "        #act = nn.ReLU\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(3, 12, kernel_size=5, padding=5//2, stride=2),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5//2, stride=2),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5//2, stride=1),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5//2, stride=1),\n",
    "            act(),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(3072, 106)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        # print(out.size())\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "net = LeNet().to(device)\n",
    "#net.apply(weights_init)\n",
    "\n",
    "net1 = LeNet_attack().to(device)\n",
    "net1.apply(weights_init)\n",
    "\n",
    "#criterion = cross_entropy_for_onehot\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AorI020iVjjS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2801, 64, 64, 3)\n",
      "(934, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data\n",
    "\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.model_selection import train_test_split\n",
    "lfw_people=fetch_lfw_people(min_faces_per_person=14,color=True,slice_=(slice(61,189),slice(61,189)),resize=0.5)\n",
    "x=lfw_people.images\n",
    "y=lfw_people.target\n",
    "\n",
    "target_names=lfw_people.target_names\n",
    "n_classes=target_names.shape[0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25,shuffle=False)\n",
    "\n",
    "\n",
    "# #two people\n",
    "# X_train_two = []\n",
    "# y_train_two = []\n",
    "# X_test_two = []\n",
    "# y_test_two = []\n",
    "# for ct_d in range(X_train.shape[0]):\n",
    "#     if  y_train[ct_d] == 6:\n",
    "#         X_train_two.append(X_train[ct_d])\n",
    "#         y_train_two.append(0)\n",
    "#     if  y_train[ct_d] == 9:\n",
    "#         X_train_two.append(X_train[ct_d])\n",
    "#         y_train_two.append(1)\n",
    "        \n",
    "# for ct_d in range(X_test.shape[0]):\n",
    "#     if  y_train[ct_d] == 6:        \n",
    "#         X_test_two.append(X_test[ct_d])\n",
    "#         y_test_two.append(0)\n",
    "#     if  y_train[ct_d] == 9:\n",
    "#         X_test_two.append(X_test[ct_d])\n",
    "#         y_test_two.append(1)\n",
    "        \n",
    "# X_train = np.asarray(X_train_two)    \n",
    "# X_test = np.asarray(X_test_two)  \n",
    "# y_train = np.asarray(y_train_two)  \n",
    "# y_test = np.asarray(y_test_two)  \n",
    "\n",
    "print (X_train.shape)\n",
    "print (X_test.shape)\n",
    "\n",
    "         \n",
    "X_train = X_train.reshape(X_train.shape[0], 64, 64, 3)\n",
    "X_test = X_test.reshape(X_test.shape[0], 64, 64, 3)\n",
    "#X_train = torch.transpose\n",
    "#X_train = X_train.astype('float32')\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "x_train = torch.FloatTensor(X_train).to(device)\n",
    "x_train = x_train.transpose(2,3).transpose(1,2)\n",
    "y_train = torch.LongTensor(y_train).to(device)\n",
    "\n",
    "x_test = torch.FloatTensor(X_test).to(device)\n",
    "x_test = x_test.transpose(2,3).transpose(1,2)\n",
    "y_test = torch.LongTensor(y_test).to(device)\n",
    "\n",
    "\n",
    "training = data.TensorDataset(x_train,y_train)\n",
    "\n",
    "testing = data.TensorDataset(x_test,y_test)\n",
    "\n",
    "dst_tensor=training\n",
    "\n",
    "criterion_train = nn.CrossEntropyLoss()\n",
    "optimizer_train = optim.Adam(net.parameters(),lr=0.01)#,momentum=0.9)\n",
    "trainloader = torch.utils.data.DataLoader(training,batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AorI020iVjjS",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fininshed training\n",
      "0.007494646680942184\n",
      "fininshed testing\n"
     ]
    }
   ],
   "source": [
    "iter_ = 0\n",
    "for epoch in range(0):\n",
    "\n",
    "    for i,data in enumerate(trainloader,0):\n",
    "   \n",
    "        #if epoch>=1:\n",
    "        if i==1:\n",
    "            #break\n",
    "            iter_=iter_+1\n",
    "            #print (iter_)\n",
    "            inputs,label = data\n",
    "\n",
    "            inputs,label =  Variable(inputs),Variable(label) \n",
    "\n",
    "            optimizer_train.zero_grad()\n",
    "\n",
    "\n",
    "            outputs_benign=net(inputs)\n",
    "            #outputs_benign = F.softmax(outputs_benign, dim=-1)\n",
    "            #print (outputs_benign[0])\n",
    "\n",
    "\n",
    "            loss_benign =  criterion_train(outputs_benign,label)\n",
    "\n",
    "            #print(\"loss computed\")\n",
    "            loss_benign.backward()\n",
    "            #print(\"loss BP\")\n",
    "            optimizer_train.step()\n",
    "\n",
    "            #if i%2000==0:\n",
    "            print (loss_benign.item())\n",
    "            #torch.save(net.state_dict(),'./LFW_net.pth')  \n",
    "       \n",
    "  \n",
    "print ('fininshed training')\n",
    "total = len(y_test)\n",
    "acc =0.0\n",
    "for ct in range(total):\n",
    "    testing_data = tt(testing[ct][0].cpu())\n",
    "    testing_data1 = tp(testing_data).to(device)\n",
    "    testing_data2 = testing_data1.view(1, *testing_data1.size())\n",
    "    y_pred = net(testing_data2)\n",
    "    predicted = torch.argmax(y_pred)\n",
    "  \n",
    "    if predicted == y_test[ct]:\n",
    "        acc=acc+1\n",
    "accuracy = acc / total\n",
    "print (accuracy)\n",
    "print ('fininshed testing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "VjKWqs2akepH",
    "outputId": "586bcc5a-f4ea-46ce-b510-edbb20f603ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 3, 64, 64])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 106])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "######### honest partipant #########\n",
    "img_index = 0   #use img_index\n",
    "dst_pil = tt(dst_tensor[img_index][0].cpu())   #use img_index\n",
    "\n",
    "gt_data = tp(dst_pil).to(device)\n",
    "gt_data = torch.unsqueeze(gt_data,0)\n",
    "\n",
    "gt_label = dst_tensor[img_index][1].long().to(device) #use img_index\n",
    "gt_label = gt_label.view(1, )\n",
    "gt_onehot_label = label_to_onehot(gt_label, num_classes=106)\n",
    "\n",
    "plt.imshow(dst_pil)\n",
    "#plt.savefig(\"./original/index_%s_label_%s\"%(img_index,gt_label.item()))\n",
    "\n",
    "\n",
    "\n",
    "batch = 100  #\n",
    "for bat in range(batch-1):\n",
    "    dst_pil = tt(dst_tensor[img_index+1+bat][0].cpu())   #use img_index\n",
    "    tmp = torch.unsqueeze(tp(dst_pil).to(device),0)\n",
    "    #print(tmp.shape)\n",
    "    gt_data = torch.cat((gt_data,tmp),0)\n",
    "    \n",
    "    gt_label_tmp = dst_tensor[img_index+1+bat][1].long().to(device) #use img_index\n",
    "    gt_label_tmp = gt_label_tmp.view(1, )\n",
    "    gt_label = torch.cat((gt_label,gt_label_tmp),0)\n",
    "    gt_onehot_label = torch.cat((gt_onehot_label,label_to_onehot(gt_label_tmp, num_classes=106)),0)\n",
    "\n",
    "    plt.imshow(dst_pil)\n",
    "    #plt.savefig(\"./original/index_%s_label_%s\"%(bat+1,gt_label_tmp.item()))\n",
    "    \n",
    "    #plt.title(\"Ground truth image\")\n",
    "    #print(\"GT label is %d.\" % gt_label.item(), \"\\nOnehot label is %d.\" % torch.argmax(gt_onehot_label, dim=-1).item())\n",
    "\n",
    "    \n",
    "gt_label = torch.reshape(gt_label,(-1,1))    \n",
    "print (gt_data.shape)\n",
    "print (gt_label.shape)\n",
    "print (gt_onehot_label.shape)\n",
    "\n",
    "\n",
    "# compute original gradient \n",
    "dy_dx = []\n",
    "original_dy_dx=[]\n",
    "original_pred = []\n",
    "for item in range(batch):\n",
    "    gt_data_single = torch.unsqueeze(gt_data[item],0)\n",
    "    out = net(gt_data_single)\n",
    "    #y = criterion(out, gt_onehot_label[item])\n",
    "    y = criterion(out, gt_label[item])\n",
    "    dy_dx = torch.autograd.grad(y, net.parameters(),retain_graph=True)\n",
    "    original_dy_dx_tmp = list((_.detach().clone() for _ in dy_dx))\n",
    "    original_dy_dx.append(original_dy_dx_tmp)\n",
    "    out_tmp = out.detach().clone()\n",
    "    original_pred.append(out_tmp)\n",
    "    \n",
    "    \n",
    "    #dy_dx.append(torch.autograd.grad(y, net.parameters()))\n",
    "\n",
    "    \n",
    "    \n",
    "# #FOR fully-connected model only\n",
    "#     dw = net.body[0].weight\n",
    "#     db = net.body[0].bias\n",
    "#     dy_dw = torch.autograd.grad(y, dw,retain_graph=True)\n",
    "#     dy_db = torch.autograd.grad(y, db,retain_graph=True)\n",
    "\n",
    "#     print (dy_dw)\n",
    "#     #print (dy_db.shape)\n",
    "\n",
    "#     leak=dy_dw/dy_db\n",
    "\n",
    "#     print (leak.shape)\n",
    "    \n",
    "\n",
    "\n",
    "# share the gradients with other clients\n",
    "#original_dy_dx = list((_.detach().clone() for _ in dy_dx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "colab_type": "code",
    "id": "jWIbBjVPVLeq",
    "outputId": "4f24add4-1cbd-40a9-ba8d-70fefd9e1590"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy label is 59.\n",
      "stolen label is 90.\n",
      "0.670233441889286\n",
      "Dummy label is 59.\n",
      "stolen label is 89.\n",
      "0.7189175643026828\n",
      "Dummy label is 59.\n",
      "stolen label is 47.\n",
      "0.7232377961277962\n",
      "Dummy label is 59.\n",
      "stolen label is 92.\n",
      "0.719640652090311\n",
      "Dummy label is 59.\n",
      "stolen label is 16.\n",
      "0.7154821187257767\n",
      "Dummy label is 59.\n",
      "stolen label is 90.\n"
     ]
    }
   ],
   "source": [
    "# generate dummy data and label\n",
    "import time\n",
    " \n",
    "\n",
    "for item in range(100):\n",
    "    start = time.perf_counter()\n",
    "    for rd in range(1):\n",
    "\n",
    "        torch.manual_seed(10*rd)\n",
    "        #dummy_data = torch.unsqueeze(torch.randn(gt_data[item].size()),0).to(device).requires_grad_(True)\n",
    "        \n",
    "        dummy_data = torch.unsqueeze(torch.zeros(gt_data[item].size()),0).to(device).requires_grad_(True)\n",
    "        #dummy_data = torch.unsqueeze(torch.ones(gt_data[item].size()),0).to(device).requires_grad_(True)\n",
    "\n",
    "        #surrogate = torch.unsqueeze(gt_data[item+1],0)\n",
    "        #aaa = torch.rand([3,32,32])\n",
    "        #surrogate[0,:,16:48,16:48] =aaa\n",
    "        #dummy_data = surrogate.to(device).requires_grad_(True)    \n",
    "        \n",
    "        #dummy_data = torch.unsqueeze(gt_data[item+1],0).to(device).requires_grad_(True)\n",
    "        \n",
    "        #k=np.random.randint(0,100)\n",
    "        #dummy_data = torch.unsqueeze(gt_data[k],0).to(device).requires_grad_(True)\n",
    "        \n",
    "        #aaa = torch.rand([3,32,32])\n",
    "        #bbb = torch.cat((aaa,aaa),dim=1)\n",
    "        #ccc = torch.cat((bbb,bbb),dim=2)\n",
    "        #dummy_data = torch.unsqueeze(ccc,dim=0).to(device).requires_grad_(True)\n",
    "        \n",
    "        #background = torch.unsqueeze(torch.zeros(gt_data[item].size()),0)\n",
    "        #background[0,2,::] = 1\n",
    "        #dummy_data = background.to(device).requires_grad_(True)\n",
    "        \n",
    "        \n",
    "        #aaa = torch.rand([3,16,16])\n",
    "        #bbb = torch.cat((aaa,aaa),dim=1)\n",
    "        #ccc = torch.cat((bbb,bbb),dim=1)\n",
    "        #ddd = torch.cat((ccc,ccc),dim=2)\n",
    "        #eee = torch.cat((ddd,ddd),dim=2)\n",
    "        #dummy_data = torch.unsqueeze(eee,dim=0).to(device).requires_grad_(True)\n",
    "        \n",
    "        \n",
    "        #dummy_data = plt.imread(\"./attack_image/replacement_69.png\")\n",
    "        #print (dummy_data.shape)\n",
    "        #dummy_data = torch.FloatTensor(dummy_data).to(device)\n",
    "        #dummy_data = dummy_data.transpose(2,3).transpose(1,2)\n",
    "        \n",
    "        dummy_label = torch.unsqueeze(torch.randn(gt_onehot_label[item].size()),dim=0).to(device).requires_grad_(True)\n",
    "        label_pred=torch.argmin(torch.sum(original_dy_dx[item][-2], dim=-1), dim=-1).detach().reshape((1,)).requires_grad_(False)\n",
    "        #label_pred_onehot = label_to_onehot(label_pred, num_classes=106)\n",
    "\n",
    "        \n",
    "        plt.imshow(tt(dummy_data[0].cpu()))\n",
    "        plt.title(\"Dummy data\")\n",
    "        #plt.savefig(\"./random_seed/index_%s_rand_seed_%s_label_%s\"%(item,rd,torch.argmax(dummy_label, dim=-1).item()))\n",
    "\n",
    "        plt.clf()\n",
    "        print(\"Dummy label is %d.\" % torch.argmax(dummy_label, dim=-1).item())\n",
    "        print(\"stolen label is %d.\" % label_pred.item())\n",
    "        \n",
    "        \n",
    "        #optimizer = torch.optim.LBFGS([dummy_data,])\n",
    "        #optimizer = torch.optim.AdamW([dummy_data,dummy_label],lr=0.01)\n",
    "        optimizer = torch.optim.AdamW([dummy_data],lr=0.01)\n",
    "      \n",
    "       \n",
    "\n",
    "        history = []\n",
    "        for iters in range(1000):\n",
    "           \n",
    "            \n",
    "            def closure():\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                dummy_data_clip = torch.clamp(dummy_data,0,1)\n",
    "                pred = net(dummy_data_clip) \n",
    "                dummy_onehot_label = F.softmax(dummy_label, dim=-1)\n",
    "                #print (pred.shape)\n",
    "                #print (dummy_onehot_label)\n",
    "                #dummy_loss = criterion(pred, dummy_onehot_label) # TODO: fix the gt_label to dummy_label in both code and slides.\n",
    "             \n",
    "                dummy_loss = criterion(pred, label_pred)\n",
    "                dummy_dy_dx = torch.autograd.grad(dummy_loss, net.parameters(), create_graph=True)\n",
    "                #dummy_dy_dp = torch.autograd.grad(dummy_loss, dummy_data, create_graph=True)\n",
    "                #print (dummy_dy_dp[0].shape)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "                grad_diff = 0\n",
    "                grad_count = 0\n",
    "                count =0\n",
    "                for gx, gy in zip(dummy_dy_dx, original_dy_dx[item]): # TODO: fix the variablas here\n",
    "                   \n",
    "                    #if iters==500 or iters== 1200:\n",
    "                    #print (gx[0])\n",
    "                    #    print ('hahaha')\n",
    "                    #print (gy[0])\n",
    "                    lasso = torch.norm(dummy_data,p=1)\n",
    "                    ridge = torch.norm(dummy_data,p=2)\n",
    "                    grad_diff += ((gx - gy) ** 2).sum() #+ 0.0*lasso +0.01*ridge \n",
    "                    #grad_diff += (torch.abs(original_pred[item]-pred)).sum()\n",
    "\n",
    "                    \n",
    "                    \n",
    "\n",
    "                    grad_count += gx.nelement()\n",
    "                \n",
    "\n",
    "                    if count == 6:\n",
    "                        break\n",
    "                    count=count+1\n",
    "                # grad_diff = grad_diff / grad_count * 1000\n",
    "                grad_diff += ((original_pred[item]-pred)**2).sum()\n",
    "             \n",
    "                \n",
    "                \n",
    "                \n",
    "                grad_diff.backward()\n",
    "                #print (count)\n",
    "\n",
    "                #print (dummy_dy_dx)\n",
    "                #print (original_dy_dx)\n",
    "\n",
    "\n",
    "                return grad_diff\n",
    "\n",
    "\n",
    "\n",
    "            optimizer.step(closure)\n",
    "            if iters % 5 == 0: \n",
    "                current_loss = closure()\n",
    "                #if iters == 0: \n",
    "                #print (\"%.8f\" % current_loss.item())\n",
    "                #print(iters, \"%.8f\" % current_loss.item())\n",
    "            history.append(tt(dummy_data[0].cpu()))\n",
    "\n",
    "        \n",
    "        \n",
    "        plt.figure(figsize=(18, 12))\n",
    "        for i in range(100):\n",
    "           plt.subplot(10, 10, i + 1)\n",
    "           plt.imshow(history[i * 10])\n",
    "           plt.title(\"iter=%d\" % (i * 10))\n",
    "           plt.axis('off')\n",
    "        \n",
    "        #print(\"Dummy label is %d.\" % torch.argmax(dummy_label, dim=-1).item())\n",
    "        #plt.savefig(\"./attack_image/64_index_%s_rand_%s_label_%s\"%(item,rd, label_pred.item()))\n",
    "        #plt.clf()\n",
    "       \n",
    "    duration = time.perf_counter()-start\n",
    "    #print (\"Running time is %.4f.\" %(duration/10.0) )\n",
    "    print (duration/10.0 )\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "id": "aokP-jhal96-",
    "outputId": "595e775a-7f91-49a8-cfaa-384c7a320002"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(60):\n",
    "  plt.subplot(6, 10, i + 1)\n",
    "  plt.imshow(history[i * 5])\n",
    "  plt.title(\"iter=%d\" % (i * 5))\n",
    "  plt.axis('off')\n",
    "print(\"Dummy label is %d.\" % torch.argmax(dummy_label, dim=-1).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "for j in range(batch):\n",
    "    for i in range(60):\n",
    "      plt.subplot(6, 10, i + 1)\n",
    "      plt.imshow(history_batch[i * 5+j])\n",
    "      plt.title(\"iter=%d\" % (i * 5+ j))\n",
    "      plt.axis('off')\n",
    "print(\"Dummy label is %d.\" % torch.argmax(dummy_label, dim=-1).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Deep Leakage from Gradients.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
